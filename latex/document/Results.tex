\chapter{Results}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%% WF Variants Algorithms %%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%% Wirtinger Flow %%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\afterpage{%
  \clearpage % Start a new page
  \begin{algorithm}[!htbp]
    \caption{\ac{WF} suggested by \cite{Candes2014}}
      \textbf{Input}: Let $\boldsymbol{y}=\{y_i\}_{i=1}^m$ and $\{\boldsymbol{a}_i\}_{i=1}^m$ be our measurements and sampling vectors; \\
      \textbf{Parameters:}  step size $\mu$;\\
      \textbf{Initialization}: Let $\hat{\boldsymbol{z}}$, be the eigenvector corresponding to the largest eigenvalue of:
      \begin{equation}
        \boldsymbol{Y} \coloneqq \frac{1}{m}\sum_{i=1}^m y_i\boldsymbol{a}_i \boldsymbol{a}_i^*\boldsymbol{1}
      \end{equation}
      and find it using power iteration. Let also $\Lambda=\sqrt{n\sum_{i=1}^m \frac{y_i}{\|\boldsymbol{a}_i\|_X^2}}$ to be the norm estimation of the signal of interest that we are trying to recover. 
      Set $\boldsymbol{z}^{(0)}=\Lambda\hat{\boldsymbol{z}}$ for the initialization.\\
      \textbf{Update loop}: for $t=0, \ldots ,t=T-1$ do the update as:
      \begin{flalign}
        \boldsymbol{z}^{(t+1)}=\boldsymbol{z}^{(t)}- \frac{\mu_{t+1}}{\left|z_0\right|_X^2}\left(\frac{1}{m}\sum_{i=1}^{m}\left(\left|\boldsymbol{a}_i^*\boldsymbol{z}^{(t)}\right|_X-y_i\right)\left(\boldsymbol{a}_i\boldsymbol{a}_i^*\right)\boldsymbol{z}^{(t)}\right).
      \end{flalign}
      \textbf{Output} $\boldsymbol{z}^{(T)}$.
    \end{algorithm}
    \begin{itemize}
      \item Power iteration is described in almost any standard numerical linear algebra book like \cite{Trefethen2022}\cite{Demmel1997}\cite{Golub2013}. 
      \item If vectorized operations are still a thing in the future, try to formulate the algorithm in the most vectorized form possible in whatever 
      numerical framework you are using. For a first exposure to vectorized operations you can have a look at \cite{Hager2010}. For in depth understanding of 
      computer architecture that leads to the vectorized operations please refer to either \cite{Patterson2014} or \cite{Hennessy2019}.
      \item Try to port as much as computation possible from \ac{CPU} to accelerators like \ac{GPU}s and \ac{TPU}s if 
      your analysis on the porting confirms it to be worthwhile.
    \end{itemize}
    A possible PyTorch\cite{LFMAI2023} implementation using \ac{CUDA}\cite{Nvidia} is listed below as:
    % \lstinputlisting[language=Python, firstline=1,lastline=20]{./algorithms/wf.py}
    \lstinputlisting[language=Python]{./algorithms/wf.py}    
  \clearpage % End the page
}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%% Truncated Wirtinger Flow %%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\afterpage{%
  \clearpage % Start a new page
  \begin{algorithm}[!htbp]
    \caption{\ac{TWF} suggested by \cite{Chen2015}}
      \textbf{Input}: Let $\boldsymbol{y}=\{y_i\}_{i=1}^m$ and $\{\boldsymbol{a}_i\}_{i=1}^m$ be our measurements and sampling vectors; \\
      \textbf{Parameters:}  step size $\mu$;\\
      \textbf{Initialization}: Let $\hat{\boldsymbol{z}}$, be the eigenvector corresponding to the largest eigenvalue of:
      \begin{equation}
        \boldsymbol{Y} \coloneqq \frac{1}{m}\sum_{i=1}^m y_i\boldsymbol{a}_i \boldsymbol{a}_i^*\boldsymbol{1}
      \end{equation}
      and find it using power iteration. Let also $\Lambda=\sqrt{n\sum_{i=1}^m \frac{y_i}{\|\boldsymbol{a}_i\|_X^2}}$ to be the norm estimation of the signal of interest that we are trying to recover. 
      Set $\boldsymbol{z}^{(0)}=\Lambda\hat{\boldsymbol{z}}$ for the initialization.\\
      \textbf{Update loop}: for $t=0, \ldots ,t=T-1$ do the update as:
      \begin{flalign}
        \boldsymbol{z}^{(t+1)}=\boldsymbol{z}^{(t)}- \frac{\mu_{t+1}}{\left|z_0\right|_X^2}\left(\frac{1}{m}\sum_{i=1}^{m}\left(\left|\boldsymbol{a}_i^*\boldsymbol{z}^{(t)}\right|_X-y_i\right)\left(\boldsymbol{a}_i\boldsymbol{a}_i^*\right)\boldsymbol{z}^{(t)}\right).
      \end{flalign}
      \textbf{Output} $\boldsymbol{z}^{(T)}$.
    \end{algorithm}
    \begin{itemize}
      \item Power iteration is described in almost any standard numerical linear algebra book like \cite{Trefethen2022}\cite{Demmel1997}\cite{Golub2013}. 
      \item If vectorized operations are still a thing in the future, try to formulate the algorithm in the most vectorized form possible in whatever 
      numerical framework you are using. For a first exposure to vectorized operations you can have a look at \cite{Hager2010}. For in depth understanding of 
      computer architecture that leads to the vectorized operations please refer to either \cite{Patterson2014} or \cite{Hennessy2019}.
      \item Try to port as much as computation possible from \ac{CPU} to accelerators like \ac{GPU}s and \ac{TPU}s if 
      your analysis on the porting confirms it to be worthwhile.
    \end{itemize}
    A possible PyTorch\cite{LFMAI2023} implementation using \ac{CUDA}\cite{Nvidia} is listed below as:
    % \lstinputlisting[language=Python, firstline=1,lastline=20]{./algorithms/twf.py}
    \lstinputlisting[language=Python]{./algorithms/twf.py}    
  \clearpage % End the page
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%% Reshaped Wirtinger Flow %%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\afterpage{%
  \clearpage % Start a new page
  \begin{algorithm}[!htbp]
    \caption{\ac{RWF} suggested by \cite{Zhang2016}}
      \textbf{Input}: Let $\boldsymbol{y}=\{y_i\}_{i=1}^m$ and $\{\boldsymbol{a}_i\}_{i=1}^m$ be our measurements and sampling vectors; \\
      \textbf{Parameters:}  step size $\mu$;\\
      \textbf{Initialization}: Let $\hat{\boldsymbol{z}}$, be the eigenvector corresponding to the largest eigenvalue of:
      \begin{equation}
        \boldsymbol{Y} \coloneqq \frac{1}{m}\sum_{i=1}^m y_i\boldsymbol{a}_i \boldsymbol{a}_i^*\boldsymbol{1}
      \end{equation}
      and find it using power iteration. Let also $\Lambda=\sqrt{n\sum_{i=1}^m \frac{y_i}{\|\boldsymbol{a}_i\|_X^2}}$ to be the norm estimation of the signal of interest that we are trying to recover. 
      Set $\boldsymbol{z}^{(0)}=\Lambda\hat{\boldsymbol{z}}$ for the initialization.\\
      \textbf{Update loop}: for $t=0, \ldots ,t=T-1$ do the update as:
      \begin{flalign}
        \boldsymbol{z}^{(t+1)}=\boldsymbol{z}^{(t)}- \frac{\mu_{t+1}}{\left|z_0\right|_X^2}\left(\frac{1}{m}\sum_{i=1}^{m}\left(\left|\boldsymbol{a}_i^*\boldsymbol{z}^{(t)}\right|_X-y_i\right)\left(\boldsymbol{a}_i\boldsymbol{a}_i^*\right)\boldsymbol{z}^{(t)}\right).
      \end{flalign}
      \textbf{Output} $\boldsymbol{z}^{(T)}$.
    \end{algorithm}
    \begin{itemize}
      \item Power iteration is described in almost any standard numerical linear algebra book like \cite{Trefethen2022}\cite{Demmel1997}\cite{Golub2013}. 
      \item If vectorized operations are still a thing in the future, try to formulate the algorithm in the most vectorized form possible in whatever 
      numerical framework you are using. For a first exposure to vectorized operations you can have a look at \cite{Hager2010}. For in depth understanding of 
      computer architecture that leads to the vectorized operations please refer to either \cite{Patterson2014} or \cite{Hennessy2019}.
      \item Try to port as much as computation possible from \ac{CPU} to accelerators like \ac{GPU}s and \ac{TPU}s if 
      your analysis on the porting confirms it to be worthwhile.
    \end{itemize}
    A possible PyTorch\cite{LFMAI2023} implementation using \ac{CUDA}\cite{Nvidia} is listed below as:
    % \lstinputlisting[language=Python, firstline=1,lastline=20]{./algorithms/rwf.py}
    \lstinputlisting[language=Python]{./algorithms/rwf.py}    
  \clearpage % End the page
}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%% Incrementally Reshaped Wirtinger Flow %%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\afterpage{%
  \clearpage % Start a new page
  \begin{algorithm}[!htbp]
    \caption{\ac{IRWF} suggested by \cite{Zhang2016}}
      \textbf{Input}: Let $\boldsymbol{y}=\{y_i\}_{i=1}^m$ and $\{\boldsymbol{a}_i\}_{i=1}^m$ be our measurements and sampling vectors; \\
      \textbf{Parameters:}  step size $\mu$;\\
      \textbf{Initialization}: Let $\hat{\boldsymbol{z}}$, be the eigenvector corresponding to the largest eigenvalue of:
      \begin{equation}
        \boldsymbol{Y} \coloneqq \frac{1}{m}\sum_{i=1}^m y_i\boldsymbol{a}_i \boldsymbol{a}_i^*\boldsymbol{1}
      \end{equation}
      and find it using power iteration. Let also $\Lambda=\sqrt{n\sum_{i=1}^m \frac{y_i}{\|\boldsymbol{a}_i\|_X^2}}$ to be the norm estimation of the signal of interest that we are trying to recover. 
      Set $\boldsymbol{z}^{(0)}=\Lambda\hat{\boldsymbol{z}}$ for the initialization.\\
      \textbf{Update loop}: for $t=0, \ldots ,t=T-1$ do the update as:
      \begin{flalign}
        \boldsymbol{z}^{(t+1)}=\boldsymbol{z}^{(t)}- \frac{\mu_{t+1}}{\left|z_0\right|_X^2}\left(\frac{1}{m}\sum_{i=1}^{m}\left(\left|\boldsymbol{a}_i^*\boldsymbol{z}^{(t)}\right|_X-y_i\right)\left(\boldsymbol{a}_i\boldsymbol{a}_i^*\right)\boldsymbol{z}^{(t)}\right).
      \end{flalign}
      \textbf{Output} $\boldsymbol{z}^{(T)}$.
    \end{algorithm}
    \begin{itemize}
      \item Power iteration is described in almost any standard numerical linear algebra book like \cite{Trefethen2022}\cite{Demmel1997}\cite{Golub2013}. 
      \item If vectorized operations are still a thing in the future, try to formulate the algorithm in the most vectorized form possible in whatever 
      numerical framework you are using. For a first exposure to vectorized operations you can have a look at \cite{Hager2010}. For in depth understanding of 
      computer architecture that leads to the vectorized operations please refer to either \cite{Patterson2014} or \cite{Hennessy2019}.
      \item Try to port as much as computation possible from \ac{CPU} to accelerators like \ac{GPU}s and \ac{TPU}s if 
      your analysis on the porting confirms it to be worthwhile.
    \end{itemize}
    A possible PyTorch\cite{LFMAI2023} implementation using \ac{CUDA}\cite{Nvidia} is listed below as:
    % \lstinputlisting[language=Python, firstline=1,lastline=20]{./algorithms/wf.py}
    \lstinputlisting[language=Python]{./algorithms/irwf.py}    
  \clearpage % End the page
}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%% Incrementally Mini-Batch Reshaped Wirtinger Flow %%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\afterpage{%
  \clearpage % Start a new page
  \begin{algorithm}[!htbp]
    \caption{\ac{IMRWF} suggested by \cite{Zhang2016}}
      \textbf{Input}: Let $\boldsymbol{y}=\{y_i\}_{i=1}^m$ and $\{\boldsymbol{a}_i\}_{i=1}^m$ be our measurements and sampling vectors; \\
      \textbf{Parameters:}  step size $\mu$;\\
      \textbf{Initialization}: Let $\hat{\boldsymbol{z}}$, be the eigenvector corresponding to the largest eigenvalue of:
      \begin{equation}
        \boldsymbol{Y} \coloneqq \frac{1}{m}\sum_{i=1}^m y_i\boldsymbol{a}_i \boldsymbol{a}_i^*\boldsymbol{1}
      \end{equation}
      and find it using power iteration. Let also $\Lambda=\sqrt{n\sum_{i=1}^m \frac{y_i}{\|\boldsymbol{a}_i\|_X^2}}$ to be the norm estimation of the signal of interest that we are trying to recover. 
      Set $\boldsymbol{z}^{(0)}=\Lambda\hat{\boldsymbol{z}}$ for the initialization.\\
      \textbf{Update loop}: for $t=0, \ldots ,t=T-1$ do the update as:
      \begin{flalign}
        \boldsymbol{z}^{(t+1)}=\boldsymbol{z}^{(t)}- \frac{\mu_{t+1}}{\left|z_0\right|_X^2}\left(\frac{1}{m}\sum_{i=1}^{m}\left(\left|\boldsymbol{a}_i^*\boldsymbol{z}^{(t)}\right|_X-y_i\right)\left(\boldsymbol{a}_i\boldsymbol{a}_i^*\right)\boldsymbol{z}^{(t)}\right).
      \end{flalign}
      \textbf{Output} $\boldsymbol{z}^{(T)}$.
    \end{algorithm}
    \begin{itemize}
      \item Power iteration is described in almost any standard numerical linear algebra book like \cite{Trefethen2022}\cite{Demmel1997}\cite{Golub2013}. 
      \item If vectorized operations are still a thing in the future, try to formulate the algorithm in the most vectorized form possible in whatever 
      numerical framework you are using. For a first exposure to vectorized operations you can have a look at \cite{Hager2010}. For in depth understanding of 
      computer architecture that leads to the vectorized operations please refer to either \cite{Patterson2014} or \cite{Hennessy2019}.
      \item Try to port as much as computation possible from \ac{CPU} to accelerators like \ac{GPU}s and \ac{TPU}s if 
      your analysis on the porting confirms it to be worthwhile.
    \end{itemize}
    A possible PyTorch\cite{LFMAI2023} implementation using \ac{CUDA}\cite{Nvidia} is listed below as:
    % \lstinputlisting[language=Python, firstline=1,lastline=20]{./algorithms/wf.py}
    % \lstinputlisting[language=Python]{./algorithms/imwf.py}    
  \clearpage % End the page
}