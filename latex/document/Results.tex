\chapter{Results}\label{ch:results}

First we explain the inspiration that put us on the path we took briefly and then explain the scenarios were considered. 
Due to the time limit most of what we had in mind could not be explored so we succinctly touch upon in \cref{sec:ideas_for_future_work} them in the hope of another 
brave soul picking up the torch and seeing them through.  

\section{Inspiration}

The approach we took was inspired by \cite{Gregor2010} as it is possibly the earliest successful attempt at \emph{unfolding}/\emph{unrolling}\index{\emph{unfolding}}\index{\emph{unrolling}} 
an iterative algorithm \cite{Monga2019}. The algorithm it \emph{unrolled} is named \ac{ISTA}\cite{Daubechies2003}\index{\ac{ISTA}} and was devised to solve \srp\index{\srp} which much like the \pr\cite{Shechtman2015}\cite{Jaganathan2015}\index{\pr} is an inverse problem\cite{Kirsch2021}\index{inverse problem} in computational imaging\index{computational imaging}\cite{Khare2023}.

\subsection{Sparse Recovery Problem}

Let $\boldsymbol{y} \in \mathbb{R}^m$ and $\boldsymbol{W} \in \mathbb{R}^{m \times n}$($n > m$, \emph{overcompleted dictionary}
\footnote{In signal/image processing terms a \emph{dictionary} allows you to represent the desired signal/image as a linear combination of some basic elements which sometimes are also called \emph{atoms}.}
the \srp\index{\srp} problem is to find a \emph{sparse}\footnote{A representation of a signal/image in a specific basis is said to be \emph{sparse} if 
the vector representing the signal/image in the said basis has lots of \emph{zeros}.} 
$\boldsymbol{x} \in \mathbb{R}^n$ in a way that it satisfies either $\boldsymbol{y} = \boldsymbol{W}\boldsymbol{x}$(noise free) or $\boldsymbol{y} \approx \boldsymbol{W}\boldsymbol{x}$(noisy).
The \ac{LASSO}\cite{Hastie2009}\index{\ac{LASSO}} formulation of the problem will be:
\begin{equation*}
  \min_{\boldsymbol{x}} \frac{1}{2} \left|\left|\boldsymbol{y}-\boldsymbol{W}\boldsymbol{x}\right|\right|_2^2 + \lambda \left|\left|\boldsymbol{x}\right|\right|_1
\end{equation*}
where the $\left|\left|\boldsymbol{\cdot}\right|\right|_1$ and $\left|\left|\boldsymbol{\cdot}\right|\right|_2$ are the usual $1$-norm and the $2$-norm that were defined in \cref{def:p-norm}, and $\lambda$ is the amount of regularization\cite{Hastie2009}. 
The \ac{ISTA}\cite{Daubechies2003}\index{ISTA} solves the \ac{LASSO}\cite{Hastie2009}\index{\ac{LASSO}} formulation by an iterative algorithm of the form:
\begin{equation*}
  \boldsymbol{x}_{k+1} = \mathcal{S}_\lambda\left(\left(\mathcal{I}-\frac{1}{\mu}\boldsymbol{W}^T\boldsymbol{W}\right)\boldsymbol{x}_k+\frac{1}{\mu}\boldsymbol{W}^T\left(\boldsymbol{y}\right)\right)
\end{equation*}
where $\mathcal{S}_\lambda$ is the elementwise soft thresholding operator, the manifestation of the $\mathrm{prox}$ operator in 
the presence of the regularization term($\lambda\left|\left|\boldsymbol{.}\right|\right|_1$), in \cref{eq:pr_solution} given by:
\begin{equation*}
  \mathcal{S}_\lambda = \mathrm{sign}(\boldsymbol{z}) \boldsymbol{\cdot} \max \left\{\left|\boldsymbol{z}\right|-\lambda,\boldsymbol{0}\right\}
\end{equation*}
where $\mathcal{I}$ is the identity matrix of size $n \times n$, $\left|\boldsymbol{\cdot}\right|$ the \emph{elementwise} usual absolute value, 
$\mathrm{sign}(\boldsymbol{\cdot})$ the \emph{elementwise} usual $\mathrm{sign}$ function, and $\mu$ the largest eigenvalue of $\boldsymbol{W}^T\boldsymbol{W}$. Let $\boldsymbol{W}_t \coloneqq \mathcal{I}-\frac{1}{\mu}\boldsymbol{W}^T\boldsymbol{W}$ and 
$\boldsymbol{W}_e \coloneqq \frac{1}{\mu}\boldsymbol{W}\boldsymbol{y}$ to abstract away the details and more importantly give it the the general look of a \nn, representing the values of a layer with 
some affine transformation of values in other layers combined with the usual activation functions in \nn, and have the iterative algorithm 
as:
\begin{equation*}
  \boldsymbol{x}_{k+1} = \mathcal{S}_\lambda\left(\boldsymbol{W}_t\boldsymbol{x}_{k}+\boldsymbol{W}_e\boldsymbol{y}\right)
\end{equation*}
which can be considered as a layer of a \nn. It is worth emphasizing that 
while we are using \nns we did not use any of the usual activation functions associated with \ml/\dl. 
It would be not overselling to say that the activation functions we used in the \srp(the elementwise soft thresholding operator) is so 
specialized that it is next to impossible to come up with it out of thin air by just guessing and not closely analyzing the \srp.
In the usual \nns, activation functions are there to give flexibility to the affine transformation 
and give them the ability to approximate more and more complex mappings, but in the \du/\au setting we have naturally occurring 
nonlinearities(coming from the domain knowledge of the problem) that will serve as the activation 
functions. Stacking the layers $L$ times would give the \emph{unfolded}/\emph{unrolled} version which is exactly the original \ac{ISTA} algorithm but with 
trainable parameters that can be \emph{learned} thanks to the \ml/\dl approaches.

\subsection{LISTA and Ada-LISTA}

Quite naturally \cite{Gregor2010} went for training the $\boldsymbol{W}_t$ and the $\boldsymbol{W}_e$ to get some improvements 
from the original \ac{ISTA}\cite{Daubechies2003}\index{\ac{ISTA}} algorithm. It is natural as they kept the intrinsic 
nonlinearities coming from the iterative solution(to benefit from the domain knowledge of the problem). 
They also replaced single $\lambda$ with a vector of $\lambda$s which can be interpreted as an adaptive gradient descent 
much like the momentum based ones \cite{Boyd2004}\cite{Nocedal2006} or the Nesterov method \cite{Nesterov2004}\cite{Nesterov2018}. 
They reported having comparable errors to that of $20L$ in the accelerated version of 
\ac{ISTA}\cite{Daubechies2003}\index{\ac{ISTA}} called \ac{FISTA}\cite{Beck2009}\index{\ac{FISTA}}, which incorporated a modified Nesterov method 
\cite{Nesterov2004}\cite{Nesterov2018} into \ac{ISTA}, when $L$ is large enough to have the error around $4$. Putting some level of 
restriction on the $L$ is necessary since large $L$ means you are already near the minimum and there is not much to gain 
from \emph{unfolding}/\emph{unrolling}. Another reason for using quite small $L$ is to benefit from not having too many iterations 
overall in the resulting model after the \emph{unfolded}/\emph{unrolled} model is trained(smaller $L$ corresponds to 
small required \ac{FLOPS}\index{\ac{FLOPS}} to reach the solution). \cite{Chen2018} showed the 
linear convergence of the \ac{LISTA} while in \ac{ISTA} and \ac{FISTA} and in the general setting only sub linear convergence can be 
attained \cite{Daubechies2003}\cite{Beck2009}. \cite{Aberdam2020} further improved the solutions using their method \ac{Ada-LISTA} which 
is robust in the presence of noise both in the dictionary and in the signal.


\section{Scenarios}

As \ac{WF} is the original algorithm that started the whole \ac{WF} variants and \ac{RWF} is the one that substantially improved the \ac{WF} we chose the two 
for our numerical experimentation in our \du/\au quest.We took the \ac{WF}\cite{Candes2014}\index{\ac{WF}} \cref{pseudocode:wf} and the 
\ac{RWF}\cite{Zhang2016}\index{\ac{RWF}} \cref{pseudocode:rwf} and unfolded/unrolled them $L$ times($160$ times for the \ac{WF} and $30$ times for 
the \ac{RWF}) to arrive at the \ac{UWF} and the \ac{URWF} which are basically just some \nn\cite{Goodfellow2016}\cite{Bishop2006}\index{\nn} 
with some special architecture(innate nonlinearities replacing the usual activation functions). The special architectures in the \ac{UWF} and the \ac{URWF} 
just like \ac{LISTA} are due to the nonlinearities that could not have been guessed and are only available to us by close inspection of the gradient that make 
the \ac{WF} and the \ac{RWF} tick in \cref{eq:gradient_pr_solution}. First nonlinearity is $\varphi \colon \mathbb{C} \rightarrow \mathbb{R}$ and the second $\varphi' \colon \mathbb{C} \rightarrow \mathbb{C}$ both elementwise. 
$\varphi$ and $\varphi'$ being elementwise is essential and Without it \ml/\dl can not be carried out. 
Data are synthetic and the assumptions to generate them are:
\begin{itemize}
  \item $\boldsymbol{x} \in \mathbb{C}^{n}, n=64$ and both the real and the complex components are drawn from the normal distribution 
  centered at zero with the standard deviation of one following the work of \cite{Naimipour2020}\cite{Naimipour2020a}.
  \item $\boldsymbol{A} \in \mathbb{C}^{m \times n}, n=64, m=640$ and both the real and the complex components are drawn from the normal distribution 
  centered at zero and with the standard deviation of one \cite{Naimipour2020}\cite{Naimipour2020a}.
  \item $\boldsymbol{y}= \left|\boldsymbol{A}\boldsymbol{x}\right|_{X} \in \mathbb{R}^m, m=640$ where $\left|\boldsymbol{.}\right|_X$ is the elementwise usual absolute value on the complex field.
  \item $N=100$ for number of sample points(pairs of $(\boldsymbol{x},\boldsymbol{y})$, for $\boldsymbol{x} \in \mathbb{C}^n$ and $\boldsymbol{y} \in \mathbb{R}^m$ ).
\end{itemize}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%% WF Variants CDP Reconstruction 10^-4 Relative Error %%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\afterpage{%
  % \clearpage % Start a new page
  \thispagestyle{empty} % No header/footer on this page
  \begin{figure}[!htbp]
    \centering
    \captionsetup{justification=centering}
    \includegraphics[width=0.7\textwidth]{./images/sat_phone_0.0001/wf_175_tef_040_rwf_045_original.png}
  \caption{Reconstruction of the Sat Phone Image Using \ac{CDP}s When the Relative Error is Almost $10^{-4}$ on all Color Channels\\
   From Top to Buttom: \ac{WF} at Iteration $175$, \ac{TWF} at Iteration $40$, \ac{RWF} at Iteration $45$, and the Original Image}
  \label{image:relative_error_0.0001}
  \end{figure}
  % \clearpage % End the page
}



On how the \ac{WF}\cite{Candes2014}\index{\ac{WF}} and the \ac{RWF}\cite{Zhang2016}\index{\ac{RWF}} are set to retrieve $\boldsymbol{x} \in \mathbb{C}^n$ up to a global phase 
please refer to \cref{pseudocode:wf} and \cref{pseudocode:rwf}. As it is evident from reconstruction of the sat phone image 
using \ac{CDP}\index{\ac{CDP}} in \cref{image:relative_error_0.0001}, the relative reconstruction error of $10^{-4}$ 
makes at least natural images quite indistinguishable when compared to the original image to the naked eye. If by unfolding/unrolling we can make 
the relative error some orders of magnitude smaller then the reconstructed images will become totally indistinguishable from the original image 
and we would be having \emph{outstandingly good} reconstruction instead of the \emph{good enough} reconstruction. The 
$L=160$ and $L=30$ are chosen with that incentive in mind(to have the relative error around $10^{-4}$ for the untrained \emph{unfolded}/\emph{unrolled} 
algorithms). Standing on the shoulders of giants \cite{Gregor2010} we try to get the said couple of orders of magnitude reduction in the relative 
error by tinkering with then update rule. 
\cite{Gregor2010}. The update rule in any \ac{WF}\cite{Liu2019}\cite{Jaganathan2015} variant in \cref{pseudocode:wf}, \ref{pseudocode:twf}, \ref{pseudocode:rwf}, \ref{pseudocode:irwf}, and \ref{pseudocode:imrwf} is of the form:
\begin{equation*}
  \boldsymbol{z}_{k+1} = \boldsymbol{z}_k - \tau\boldsymbol{\theta}[\boldsymbol{z}_k,\boldsymbol{A},\boldsymbol{A^*},\varphi]
\end{equation*}
where $\boldsymbol{\theta}[\boldsymbol{z}_k,\boldsymbol{A},\boldsymbol{A^*},\varphi]$ is a mapping that gives a vector as an output 
$\in\mathbb{C}^n$ and $\tau$ is the step size that was proposed by the respective algorithm. While just trying different mappings of the output vector might work 
some are more backed by theory and are worth exploring first. Changing the weight of the descent direction, by multiplying it by a scalar, is what most first-order adaptive gradient descent are doing in order to 
overcome the poor rate of convergence of the naive gradient descent. A linear transformation of the output vector by the means of a matrix-vector product is the next step 
and is the equivalent of finding better \emph{descent directions} or faster route to reach the minimum through changing of the \emph{scalar product} that induces our distance.
Assume that the algorithms are unfolded/unrolled $L$ times, 
we considered the following changes to the update rule and learning the associated parameters: 

\begin{enumerate}
  \item $\boldsymbol{z}_{k+1} = \boldsymbol{z}_k - \tau\boldsymbol{\theta}[\boldsymbol{z}_k,\boldsymbol{A},\boldsymbol{A^*},\varphi]$ 
  and learning the single scalar $\tau \in \mathbb{R}$ as to try and find a better gradient descent with constant step size,
  \item $\boldsymbol{z}_{k+1} = \boldsymbol{z}_k - \tau_k\boldsymbol{\theta}[\boldsymbol{z}_k,\boldsymbol{A},\boldsymbol{A^*},\varphi]$
  and learning $L$ scalars $\tau_k\in\mathbb{R}$ as to try and find a better adaptive gradient descent with large step sizes when possible 
  and small step sizes while being in \emph{stiff} regions, 
  \item $\boldsymbol{z}_{k+1} = \boldsymbol{z}_k - \boldsymbol{S}\boldsymbol{\theta}[\boldsymbol{z}_k,\boldsymbol{A},\boldsymbol{A^*},\varphi]$
  and learning a single semi-positive definite matrix $\boldsymbol{S}\in \mathbb{R}^{n\times n}$ as to try and find a better descent direction while 
  ensuring being always on the descent direction by the semi-positive definite constraint,
  \item $\boldsymbol{z}_{k+1} = \boldsymbol{z}_k - \boldsymbol{M}\boldsymbol{\theta}[\boldsymbol{z}_k,\boldsymbol{A},\boldsymbol{A^*},\varphi]$
  and learning a single general matrix $\boldsymbol{M}\in \mathbb{R}^{n\times n}$ as to try and find a better descent direction while 
  while not forcing the semi-positive definite constraint and hoping for the best,
  \item $\boldsymbol{z}_{k+1} = \boldsymbol{z}_k - \tau_k\boldsymbol{S}\boldsymbol{\theta}[\boldsymbol{z}_k,\boldsymbol{A},\boldsymbol{A^*},\varphi]$
  and learning a single semi-positive definite matrix $\boldsymbol{S}\in \mathbb{R}^{n\times n}$ and $L$ scalars $\tau_k \in \mathbb{R}$ as to try and find a 
  better descent direction with variable step sizes while \emph{trying} to ensure to be always on the descent direction by the semi-positive definite constraint(there is
  the possibility that the optimizer goes for a negative step sizes $\tau_k \in \mathbb{R}$), 
  \item $\boldsymbol{z}_{k+1} = \boldsymbol{z}_k - \tau_k\boldsymbol{M}\boldsymbol{\theta}[\boldsymbol{z}_k,\boldsymbol{A},\boldsymbol{A^*},\varphi]$
  and learning a single general matrix $\boldsymbol{M}\in \mathbb{R}^{n\times n}$ and $L$ scalars $\tau_k \in \mathbb{R}$ as to try and find a 
  better descent direction with variable step sizes while not forcing the semi-positive definite constraint and hoping for the best,
  \item $\boldsymbol{z}_{k+1} = \boldsymbol{z}_k - \boldsymbol{S}_k\boldsymbol{\theta}[\boldsymbol{z}_k,\boldsymbol{A},\boldsymbol{A^*},\varphi]$ 
  and learning $L$ semi-positive definite matrices $\boldsymbol{S}\in \mathbb{R}^{n\times n}$ as to try and find a better descent direction while 
  ensuring being always on the descent direction by the semi-positive definite constraint,
  \item $\boldsymbol{z}_{k+1} = \boldsymbol{z}_k - \boldsymbol{M}_k\boldsymbol{\theta}[\boldsymbol{z}_k,\boldsymbol{A},\boldsymbol{A^*},\varphi]$ 
  and learning $L$ general matrices $\boldsymbol{M}\in \mathbb{R}^{n\times n}$ as to try and find a better descent direction while 
  while not forcing the semi-positive definite constraint and hoping for the best,
\end{enumerate}
and we call them \emph{scenarios}. It is worth emphasizing that while from the parameter space point of view alone some scenarios are 
contained in others we explore them separately. The reasons include:

\begin{itemize}
  \item to come up with a model that has as few as possible parameters while still having 
  good performances on the train and the test data , which is one of the central ideas behind 
  \du/\au\cite{Shechtman2015}\index{\du}\index{\au}, and not a full blown general \ml/\dl model.
  \item not to confuse the optimizers unintentionally by introducing too many parameters \cite{Sankararaman2019}.
  \item not to overparameterize and in turn introducing overfitting\cite{Bishop2006}\cite{Goodfellow2016}\cite{ShalevShwartz2014}.
  \item not to burn too many \ac{FLOPS}\index{\ac{FLOPS}} needlessly.
\end{itemize}
As to stress the first bullet point the scenarios were sorted in the ascending order in terms of trainable parameters as one of our \emph{main} goals 
is to come up with a model with satisfactory improvement over the original algorithm by using as few as possible number of trainable parameters. 
The practitioner that wants to replicate the current study(or any other in the realm of \du/\au for that matter) is strongly encouraged to bid 
their time and start from scenario $1$ with $1$ trainable parameter and conclude with scenario $8$ with $Ln^2$ trainable parameters(or whatever 
that applies in their context).

During the training we go with the following setting:
\begin{itemize}
  \item initializing the trainable parameters in a way that at the beginning of the training the model coincides with the original iterative algorithm. 
  This is very crucial as in realistic settings the convergence of the original algorithm that is being \emph{unfolded}/\emph{unrolled} has conditions and 
  assumptions behind it which makes it is very dangerous to deviate from the proposed parameter setup. In fact during the prototyping phase of our own work 
  we faced divergence in the error before we even reached $1$ epoch 
  just because we forgot to act accordingly in the parameter setup that was proposed in the \ac{WF} and in the \ac{RWF}.    
  \item \adam\cite{Kingma2014}\index{\adam} as the optimizer with the starting 
  pseudo learning rate of $\mathrm{lr}=1.000\times10^{-3}$ which is 
  recommended\cite{Kingma2014}\cite{Sun2019}.
  \item taking $2$\cite{Masters2018} samples for the mini-batch stochastic gradient descent 
  that is wrapped inside \adam\cite{Kingma2014}\index{\adam}. Small batch sizes have the 
  disadvantage of introducing noise during the training process but at the same time make 
  the training process faster. They can also contribute to better generalization ability 
  of the \ml/\dl model \cite{Masters2018}.
  \item splitting the data into the train data and the test data with the ratio of $9$ to $1$ 
  in each epoch  not to overfit \cite{Goodfellow2016}\cite{Chollet2023}.
  \item tracking the relative error of the original algorithm \emph{unfolded}/\emph{unrolled} $L$ times 
  and the being trained network on train and test data as to decide on the generalization ability of the model \cite{Goodfellow2016}\cite{Chollet2023}.
\end{itemize}

The results of the training process for $50$ epochs for the first $3$ scenarios for the \ac{UWF} can be seen in \cref{fig:uwf_training_01_02_03}, the second $3$ scenarios in \cref{fig:uwf_training_04_05_06} and the 
last $2$ scenarios in \cref{fig:uwf_training_07_08_optuna} while keeping the pseudo learning rate the recommended $\mathrm{lr}=10^{-3}$ \cite{Kingma2014}\cite{Sun2019}. 
Similarly for the case of \ac{URWF} the results can be found in \cref{fig:urwf_training_01_02_03}, \cref{fig:urwf_training_04_05_06}, and \cref{fig:urwf_training_07_08_optuna}. 
In these figures we are looking for a couple of orders of magnitude decrease in the error for the model that is being trained both on the train 
and on the test data to ensure that our model has the much coveted \emph{generalizability} property. It can be seen some of the 
scenarios performed poorly(first scenario for both the \ac{UWF} and the \ac{URWF}) while some others were quite decent. The questions remains whether it is possible 
to get better results by changing the pseudo learning rate($\mathrm{lr}$) even for the case of the first scenario or more importantly 
for which one of the scenarios and what pseudo learning rate($\mathrm{lr}$) can we achieve the best performance? The stated concerns to some extent can be answered by the means of a 
\ho \cite{Hutter2019}\cite{Akiba2019} study. \HO studies help the \ml/\dl practitioners to fine-tune their models and come up with better and better set of 
parameters. \HO relies on searching through a parameter space to look for a suitable set of parameters. A parameter space is basically the cartesian 
products of the range of the parameters. Obviously the resulting set must be countable otherwise it would take infinite FLOPS and in turn infinite time to 
reach the set of parameters for the best model. That is why when facing a continuous parameter like the pseudo learning rate($\mathrm{lr}$) 
in our case the parameter must be discretized or sampled with a sampler. Discussion of the technics in the \ho realm is quite 
involved, but it should be pointed out that the level of theory backing up the \ho is somewhere between brute force methods and mathematical optimization. 
While a crude grid search and comparison in our case using the combination of \bash\cite{Ramey2022}\index{\bash}(looping over 
the grid points) and \awk\cite{Robbins2023}\index{\awk}(lazy database management for bookkeeping) could be used due to our 
small parameter space, we settled on using a domain specific package for the \ho\cite{Hutter2019}\cite{Akiba2019}\index{\ho} 
part. There are quite a number of packages that can be used for \ho\cite{Hutter2019}\cite{Akiba2019}\index{\ho} and we took the decision to go with 
\optuna\cite{Akiba2019}\index{\optuna}. Our reasons for using the \optuna\cite{Akiba2019}\index{\optuna} include but not limited to:
\begin{itemize}
  \item Use of the latest technics in \ho\cite{Hutter2019}\cite{Akiba2019}\index{\ho}.
  \item It is quite lightweight.
  \item Describing the parameter space is both easy and flexible \cite{Akiba2019}.
  \item Pruning capabilities for not-so-optimistic scenarios by implanting probes(measuring some value to decide on early stopping) \cite{Akiba2019}.
  \item Distributed computing can be done thanks to the \ac{RDBMS}s. At the $2019$ \scipy conference, the \optuna team stated that their implementation can handle up to $6$ computational nodes in the case of distributed computing.
  \item Usage of \ac{RDBMS} for bookkeeping, safekeeping(in case of crash or just rebooting) and handling of dead-locks associated with the distributed computing.
  \item Nice dashboard for better visualization and interpretation of the results.  
\end{itemize}
The range of scenarios is obvious but what about the pseudo learning rate($\mathrm{lr}$)? 
During the prototyping we observed that the $\mathrm{lr}=10^{-2}$ would result in the error exploding and $\mathrm{lr}=10^{-4}$ would perform 
inferior to the already observed $\mathrm{lr}=10^{-3}$ and that is why we set $\mathrm{lr}=10^{-4}$ and $\mathrm{lr}=10^{-2}$ 
as the lower and upper bounds on the pseudo learning rate($\mathrm{lr}$). We chose the uniform sampler for discretization of the pseudo learning rate($\mathrm{lr}$). 
Now comes the easy part where you can sit back and let the \optuna\cite{Akiba2019} go over the discrete grid at its own discretion(\ho technics \cite{Hutter2019}\cite{Akiba2019}).
After \ho\cite{Hutter2019}\cite{Akiba2019}\index{\ho} while focusing on scenarios and the pseudo learning rate($\mathrm{lr}$) in \adam\cite{Kingma2014} 
we arrive at the final proposed best scenario for the \ac{UWF} in the third subfigure of \cref{fig:uwf_training_07_08_optuna} and for the 
\ac{URWF} in the third subfigure of \cref{fig:urwf_training_07_08_optuna}. It can be seen that we were successful to reduce the error both on the train and the test data and the decrease is better that the originally models trained with $\mathrm{lr}=10^{-3}$ 
thanks to the \ho study. While it might sound like a contradiction that trained \emph{unfolded}/\emph{unrolled} supervisor \ac{RWF} algorithm
is performing similarly to the trained \emph{unfolded}/\emph{unrolled} \ac{WF} algorithm the reader must recall that \ac{RWF} is only \emph{unfolded}/\emph{unrolled} $30$ times while 
the \ac{WF} is \emph{unfolded}/\emph{unrolled} $160$ times. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%% Training UWF Without Hyperparameter Optimization %%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\afterpage{%
%   \clearpage % Start a new page
\begin{figure}[!htbp]
  \subfloat[Single Scalar$(\tau)$, $\mathrm{lr}=1.000\times10^{-3}, \,\mathrm{L}=160$]{\input{./tikz/wf/wf_s_00_l_160_e_50_lr_0.001.tex}}\\
  \subfloat[Different Scalars$(\tau_k)$, $\mathrm{lr}=1.000\times10^{-3}, \,\mathrm{L}=160$]{\input{./tikz/wf/wf_s_01_l_160_e_50_lr_0.001.tex}}\\
  \subfloat[Single Matrix$(\boldsymbol{M})$, $\mathrm{lr}=1.000\times10^{-3}, \,\mathrm{L}=160$]{\input{./tikz/wf/wf_s_02_l_160_e_50_lr_0.001.tex}}\\  
  \caption{\ac{UWF}\index{UWF} Training in Different Scenarios Without \optuna\cite{Akiba2019}}
  \label{fig:uwf_training_01_02_03}
  \end{figure}
%   \clearpage % End the page
}
\afterpage{%
%   \clearpage % Start a new page
\begin{figure}[!htbp]
  \subfloat[Single Semi-Positive Definite Matrix$(\boldsymbol{S})$, $\mathrm{lr}=1.000\times10^{-3}, \,\mathrm{L}=160$]{\input{./tikz/wf/wf_s_03_l_160_e_50_lr_0.001.tex}}\\
  \subfloat[Different Scalars Multiplied by a Single Matrix$(\tau_k\boldsymbol{M})$, $\mathrm{lr}=1.000\times10^{-3}, \,\mathrm{L}=160$]{\input{./tikz/wf/wf_s_04_l_160_e_50_lr_0.001.tex}}\\
  \subfloat[Different Scalars Multiplied by a Single Semi-Positive Definite Matrix$(\tau_k\boldsymbol{S})$, $\mathrm{lr}=1.000\times10^{-3}, \,\mathrm{L}=160$]{\input{./tikz/wf/wf_s_05_l_160_e_50_lr_0.001.tex}}\\
  \caption{\ac{UWF}\index{UWF} Training in Different Scenarios Without \optuna\cite{Akiba2019}}
  \label{fig:uwf_training_04_05_06}
  \end{figure}
%   \clearpage % End the page
}

\afterpage{%
%   \clearpage % Start a new page
\begin{figure}[!htbp]
  \subfloat[Different Matrices$(\boldsymbol{M}_k)$, $\mathrm{lr}=1.000\times10^{-3}, \,\mathrm{L}=160$]{\input{./tikz/wf/wf_s_06_l_160_e_50_lr_0.001.tex}}\\  
  \subfloat[Different Semi-Positive Definite Matrices$(\boldsymbol{S}_k)$, $\mathrm{lr}=1.000\times10^{-3}, \,\mathrm{L}=160$]{\input{./tikz/wf/wf_s_07_l_160_e_50_lr_0.001.tex}}\\  
  \subfloat[Proposed Scenario Using \optuna\cite{Akiba2019}\index{\optuna}: Different Scalars Multiplied by a Single Matrix$(\tau_k\boldsymbol{M})$, $\mathrm{lr}=8.798\times10^{-3}, \,\mathrm{L}=160$]{\input{./tikz/wf/optuna.tex}}\\  
  \caption{\ac{UWF}\index{UWF} Training in Different Scenarios With and Without \optuna\cite{Akiba2019}}
  \label{fig:uwf_training_07_08_optuna}
  \end{figure}
%   \clearpage % End the page
}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%% Training URWF Without Hyperparameter Optimization %%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\afterpage{%
%   \clearpage % Start a new page
\begin{figure}[!htbp]
  \subfloat[Single Scalar$(\tau)$, $\mathrm{lr}=1.000\times10^{-3}, \,\mathrm{L}=30$]{\input{./tikz/rwf/rwf_s_00_l_30_e_50_lr_0.001.tex}}\\
  \subfloat[Different Scalars$(\tau_k)$, $\mathrm{lr}=1.000\times10^{-3}, \,\mathrm{L}=30$]{\input{./tikz/rwf/rwf_s_01_l_30_e_50_lr_0.001.tex}}\\
  \subfloat[Single Matrix$(\boldsymbol{M})$, $\mathrm{lr}=1.000\times10^{-3}, \,\mathrm{L}=30$]{\input{./tikz/rwf/rwf_s_02_l_30_e_50_lr_0.001.tex}}\\  
  \caption{\ac{URWF}\index{URWF} Training in Different Scenarios Without \optuna\cite{Akiba2019}}
  \label{fig:urwf_training_01_02_03}
  \end{figure}
%   \clearpage % End the page
}
\afterpage{%
%   \clearpage % Start a new page
\begin{figure}[!htbp]
  \subfloat[Single Semi-Positive Definite Matrix$(\boldsymbol{S})$, $\mathrm{lr}=1.000\times10^{-3}, \,\mathrm{L}=30$]{\input{./tikz/rwf/rwf_s_03_l_30_e_50_lr_0.001.tex}}\\
  \subfloat[Different Scalars Multiplied by a Single Matrix$(\tau_k\boldsymbol{M})$, $\mathrm{lr}=1.000\times10^{-3}, \,\mathrm{L}=30$]{\input{./tikz/rwf/rwf_s_04_l_30_e_50_lr_0.001.tex}}\\
  \subfloat[Different Scalars Multiplied by a Single Semi-Positive Definite Matrix$(\tau_k\boldsymbol{S})$, $\mathrm{lr}=1.000\times10^{-3}, \,\mathrm{L}=30$]{\input{./tikz/rwf/rwf_s_05_l_30_e_50_lr_0.001.tex}}\\
  \caption{\ac{URWF}\index{URWF} Training in Different Scenarios Without \optuna\cite{Akiba2019}}
  \label{fig:urwf_training_04_05_06}
  \end{figure}
%   \clearpage % End the page
}
\afterpage{%
%   \clearpage % Start a new page
\begin{figure}[!htbp]
  \subfloat[Different Matrices$(\boldsymbol{M}_k)$, $\mathrm{lr}=1.000\times10^{-3}, \,\mathrm{L}=30$]{\input{./tikz/rwf/rwf_s_06_l_30_e_50_lr_0.001.tex}}\\  
  \subfloat[Different Semi-Positive Definite Matrices$(\boldsymbol{S}_k)$, $\mathrm{lr}=1.000\times10^{-3}, \,\mathrm{L}=30$]{\input{./tikz/rwf/rwf_s_07_l_30_e_50_lr_0.001.tex}}\\  
  \subfloat[Proposed Scenario Using \optuna\cite{Akiba2019}\index{\optuna}: Different Scalars Multiplied by a Single Matrix$(\tau_k\boldsymbol{M})$, $\mathrm{lr}=7.622\times10^{-3}, \,\mathrm{L}=30$]{\input{./tikz/rwf/optuna.tex}}\\  
  \caption{\ac{URWF}\index{URWF} Training in Different Scenarios With and Without \optuna\cite{Akiba2019}\index{\optuna}}
  \label{fig:urwf_training_07_08_optuna}
  \end{figure}
%   \clearpage % End the page
}




\section*{Ideas for Future Work}\label{sec:ideas_for_future_work}

We can think of a couple of directions to go on from here and we would like to propose them 
for future works that can be done by extending the scope of the current work.

\subsection*{Different Variants/Different Applications}

There are many \ac{WF}\cite{Jaganathan2015}\cite{Liu2019} variants out there and we can expect more to appear in the future. 
Currently \cite{Jaganathan2015}\cite{Liu2019}\cite{Chandra2017} give an overview of \ac{WF} variants and you might want to start from there for 
\du/\au\cite{Monga2019} on those variants. I for one would love to see the result of fine tuned 
\du/\au\cite{Monga2019} version of a \ac{WF} variant for a specific real world problem like \cite{Fogel2013}. The $3$-$d$ density maps reconstruction 
is a bit more involved than the synthetic natural image reconstruction we did both in terms of implementation and runtime. \cite{Candes2014} investigated the 
Nicotine and the Caffeine molecule and reported the runtimes of 
$5.4$ hours for both using a MacBook Pro with a $2.4$ GHz Intel Core i$7$ Processor and $8$ GB $1600$ MHz DDR$3$ memory. 
the homepage of Alexandre d'Aspremont contains the code and the necessary directions in case you decided to give it a shot.

\subsection*{Data}

Whenever there is measurement, there is noise. \cite{Aberdam2020} considered the the presence of noise and showed that 
their method \ac{Ada-LISTA} is robust in combating the noise to some extent therefore improving the work of \cite{Gregor2010}.
The effectiveness of an \emph{unfolded}/\emph{unrolled} \ac{WF} variant in the face of different types of noise in the measurements or in the operator $\boldsymbol{A}$ 
is worth exploring. 


\subsection*{Different Algorithms/Parameters}

Depending on the function we are trying to minimize and the iterative \ac{WF}\cite{Jaganathan2015}\cite{Liu2019} variant algorithm we are \emph{unfolding}/\emph{unrolling} 
it is possible to investigate other scenarios for parameter learning too. Possible candidates are but not limited to:
\begin{itemize}
  \item Adjoint operator $\boldsymbol{A}^*$(different parameters)
  \item Giving weights to the sampling operation by introducing $\boldsymbol{C}\in \mathbb{C}^{K\times N}$ and 
  $\left|\left|\phi(\boldsymbol{A}_j\psi)-\boldsymbol{G}_j\right|\right|_X^2 \rightarrow \left|\left|\boldsymbol{C}_j \odot \left(\phi(\boldsymbol{A}_j\psi)-\boldsymbol{G}_j\right)\right|\right|_X^2$ 
  where $\boldsymbol{C}_j$s are the rows of the matrix $\boldsymbol{C}$(different parameters).
  \item The presence of a regularizer to impose the desired conditions on the solutions(e.g. \emph{sparsity}) or to combat noise or overfitting(different algorithm).
\end{itemize}















