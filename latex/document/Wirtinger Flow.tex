\chapter{Wirtinger Flow}

The whole thing about \emph{\ac{WF}} variants started with the seminal work of \cite{Candes2014}.
The most important improvements chronologically were done by \cite{Chen2015}, \cite{Kolte2016}, and\cite{Zhang2016}
with the nicknames of \ac{TWF}, \ac{ITWF}, \ac{RWF}, \ac{IRWF}, and \ac{IMRWF}.
For a quite extensive survey on \emph{\ac{WF}} variants please refer to Liu et al.\cite{Liu2019}. Chandra et al.\cite{Chandra2017} 
gathered quite number of \emph{Phase Retrieval} methods including a couple of \emph{\ac{WF}} variants in the MATLAB\textregistered\space 
problem solving environment in a uniform manner.\\
We quickly go over the problem formulation, difficulties, algorithms, and at the of the chapter we give some numerical experiments we are going
to refer to in the subsequent chapters.

\section{Problem Formulation}
Consider the ray $\boldsymbol{x} \in \mathbb{C}^{n \times 1}$ is emitted onto the object of interest and the diffracted rays are measured as 
$\boldsymbol{y} \in \mathbb{R}^{m \times 1}$ and is connected to the original ray by $\boldsymbol{y} = \varphi(\boldsymbol{A}\boldsymbol{x})$,
where $\boldsymbol{A} \in \mathbb{C}^{m \times n}$ and $\varphi$ the usual element-wise absolute value(or the squared absolute value) from 
$\mathbb{C}^{m \times 1}$ to $\mathbb{R}^{m \times 1}$.\\
Candes and Soltanolkotabi\cite{Candes2014} considered $\varphi$ to be squared element-wise absolute value and the loss function to be quadratic. 
The summary for all the variants in terms of formulation is in table\ref{tab:formulation}  


\begin{table}
	\centering
	\begin{tabular}{||c l c||} 
	 \hline
	 \emph{\ac{WF}} Variant & $\varphi$ 						& loss functions\\ [0.5ex] 
	 \hline\hline
	 \ac{WF}                & $\left|\boldsymbol{z}\right|^2$ 	& quadratic 	\\ 
	 \ac{TWF}   			& $\left|\boldsymbol{z}\right|^2$ 	& quadratic 	\\
	 \ac{ITWF}              & $\left|\boldsymbol{z}\right|^2$   & quadratic 	\\
	 \ac{RWF} 				& $\left|\boldsymbol{z}\right|$ 	& quadratic 	\\
	 \ac{IRWF} 	            & $\left|\boldsymbol{z}\right|$ 	& quadratic 	\\
	 \ac{IMRWF}             & $\left|\boldsymbol{z}\right|$ 	& quadratic 	\\ [1ex] 
	 \hline
	\end{tabular}
	\caption{$\varphi$ and the loss function used in \cite{Candes2014}, \cite{Chen2015}, \cite{Kolte2016}, and \cite{Zhang2016}}
	\label{tab:formulation}
	\end{table}
\section{Difficulties}

The loss function is non-convex. Set $n=1$, $m=2$, $\boldsymbol{x}_1 = \begin{pmatrix}1+i\end{pmatrix}^{1 \times 1}$, 
$\boldsymbol{x}_2 = \begin{pmatrix}-1-i\end{pmatrix}^{1 \times 1}$, $\boldsymbol{A}=\begin{pmatrix}1\\i \end{pmatrix}^{2 \times 1}$, 
$\boldsymbol{y}=\begin{pmatrix}1\\2 \end{pmatrix}^{2 \times 1}$, and $\lambda=1/2$ to build a counterexample. Non-convexity is bad news for 
optimization as it can be seen vividly in \cite{Boyd2004} and \cite{Nocedal2006}. To make the matter worse the loss function is not 
holomorphic( it can be easily seen that Cauchy-Riemann equations\cite{Rudin1987} do not hold) and therefore complex differentiability 
is out of the question\cite{Rudin1987}.

% \begin{equation} \label{prob:mainproblem}
% 	Recover $\boldsymbol{x} \in \mathbb{R}^n/\mathbb{C}^n$ from measurements $y_i$ given by
% 	\begin{flalign}
% 		y_i=\left|\langle \boldsymbol{a}_i,\mathbf{x}\rangle\right|, \quad \text{for }\; i=1,\cdots,m, \label{eq:mainproblem}
% 	\end{flalign}
% 	where $\boldsymbol{a}_i \in \mathbb{R}^n/\mathbb{C}^n$ are random design vectors (known). 
% \end{equation}













\index{Scalar Product}

















			




\begin{equation*}
	y_k = \left| \sum_{t=0}^{n-1} x[t] e^{-i2\pi\omega_kt} \right|^2 , \qquad \omega_k \in \Omega
  \end{equation*}
  
  \begin{equation*}
	y_k = \left| \sum_{t=0}^{n-1} x[t]\overline{d[t]} e^{-i2\pi\omega_kt} \right|^2 , \qquad \omega_k \in \Omega
  \end{equation*}
  
  \begin{equation*}
	y_k = \left| \sum_{t=0}^{n-1} x[t]\overline{d[t]} e^{-i2\pi\omega_kt} \right|^2 , \qquad \begin{split}
	0 &\leq k \leq n-1\\
	1 &\leq l \leq L
	\end{split}
  \end{equation*}
  
  \begin{equation*}
	\mathbb{E}\left[d\right] = 0, \qquad \mathbb{E}\left[d^2\right] = 0, \qquad\mathbb{E}\left[\left|d\right|^4\right] = 2\mathbb{E}\left[\left|d\right|^2\right]^2
  \end{equation*}
  
  Ternary Modulation
  \begin{equation*}
	d =
		\begin{cases}
			+1 & \text{with prob.  $1/4$}\\
			0 & \text{with prob.  $1/2$}\\
			-i & \text{with prob.  $1/4$}
		\end{cases}  
  \end{equation*}
  
  
  
  
  
  Octanary Modulation
  \begin{equation*}
	b_1 =
		\begin{cases}
			+1 & \text{with prob.  $1/4$}\\
			-1 & \text{with prob.  $1/4$}\\
			-i & \text{with prob.  $1/4$}\\
			+i & \text{with prob.  $1/4$}\\
  
		\end{cases}  
		\qquad \text{and} \qquad 
	b_2 
		\begin{cases}  
		  +\sqrt{2}/2 & \text{with prob.  $4/5$}\\
		  +\sqrt{3} & \text{with prob.  $1/5$}\\
	  \end{cases}   
  \end{equation*}



\begin{Thm}
	Let $X$ and $Y$ be independent discrete random variables. We would be having:
	\begin{equation*}
		E(XY) = E(X)(Y)
	\end{equation*}
\end{Thm}
\begin{Proof}
Consult a book on discrete probabilty on any other undergraduate level book on probabilty theory like \cite{Chung2003}
\end{Proof}
		
  so the $E(d)$ part becomes trivial as $b_1$ is symmetrically distributed around zero. 

  \begin{Thm}
	Let $X$ and $Y$ be independent discrete random variables. For functions of our random variables we would be having:
	\begin{equation*}
		E(f(XY)) = \sum_{x}^{}\sum_{y}^{}f(x,y)P(x)P(Y)
	\end{equation*}
\end{Thm}
\begin{Proof}
	Consult a book on discrete probabilty on any other undergraduate level book on probabilty theory like \cite{DasGupta2011}.
	The general case where $X$ and $Y$ are not independent is usually discussed. Then by assumming an independent setting 
	you will arrive at the conclusion.
	\end{Proof}



\begin{Prop}
	The Octanary Modulation setting is admissible according to \cite{Candes2014}. 
	
\end{Prop}

\begin{Proof}
	\begin{equation*}
		\begin{split}
		E(d) &= \left(+1 \times \frac{\sqrt{2}}{2}\right) \times \frac{4}{20} + \left(+1 \times \sqrt{3}\right) \times \frac{1}{20}+\left(-1 \times \frac{\sqrt{2}}{2}\right) \times \frac{4}{20}+\left(-1 \times \sqrt{3}\right) \times \frac{1}{20}\\
		     &+ \left(+i \times \frac{\sqrt{2}}{2}\right) \times \frac{4}{20} + \left(+i \times \sqrt{3}\right) \times \frac{1}{20}+\left(-i \times \frac{\sqrt{2}}{2}\right) \times \frac{4}{20}+\left(-i \times \sqrt{3}\right) \times \frac{1}{20}\\ 
			 &= 0
		\end{split}
	  \end{equation*}
	  \begin{equation*}
		\begin{split}
		E(d^2) &= \left(+1 \times \frac{1}{2}\right) \times \frac{4}{20} + \left(+1 \times 3\right) \times \frac{1}{20}+\left(+1 \times \frac{1}{2}\right) \times \frac{4}{20}+\left(+1 \times 3\right) \times \frac{1}{20}\\
		     &+ \left(-1 \times \frac{1}{2}\right) \times \frac{4}{20} + \left(-1 \times 3\right) \times \frac{1}{20}+\left(-1 \times \frac{1}{2}\right) \times \frac{4}{20}+\left(-1 \times 3\right) \times \frac{1}{20}\\ 
			 &= 0
		\end{split}
	 \end{equation*}
	 \begin{equation*}
		\begin{split}
		E(\left|d\right|^2) &= \left(\left|+1 \times \frac{\sqrt{2}}{2} \right|\right)^2\times \frac{4}{20} + \left(\left|+1 \times \sqrt{3}\right|\right)^2\times \frac{1}{20}\\
		                    &+\left(\left|-1 \times \frac{\sqrt{2}}{2}\right|\right)^2\times \frac{4}{20}+\left(\left|-1 \times \sqrt{3}\right|\right)^2\times \frac{1}{20}\\
		                    &+ \left(\left|+i \times \frac{\sqrt{2}}{2}\right|\right)^2\times \frac{4}{20} + \left(\left|+i \times \sqrt{3}\right|\right)^2\times \frac{1}{20}\\
							&+\left(\left|-i \times \frac{\sqrt{2}}{2}\right|\right)^2\times \frac{4}{20}+\left(\left|-i \times \sqrt{3}\right|\right)^2\times \frac{1}{20}\\ 
			 &= 1
		\end{split}
	  \end{equation*}
	  \begin{equation*}
		\begin{split}
		E(\left|d\right|^4) &= \left(\left|+1 \times \frac{\sqrt{2}}{2}\right|\right)^4 \times \frac{4}{20} + \left(\left|+1 \times \sqrt{3}\right|\right)^4 \times \frac{1}{20}\\
		                    &+\left(\left|-1 \times \frac{\sqrt{2}}{2}\right|\right)^4 \times \frac{4}{20}+\left(\left|-1 \times \sqrt{3}\right|\right)^4 \times \frac{1}{20}\\
		                    &+ \left(\left|+i \times \frac{\sqrt{2}}{2}\right|\right)^4 \times \frac{4}{20} + \left(\left|+i \times \sqrt{3}\right|\right)^4 \times \frac{1}{20}\\
							&+\left(\left|-i \times \frac{\sqrt{2}}{2}\right|\right)^4 \times \frac{4}{20}+\left(\left|-i \times \sqrt{3}\right|\right)^4 \times \frac{1}{20}\\ 
			 &= 2
		\end{split}
	 \end{equation*}
	 which closes the proof.
\end{Proof}




\begin{Prop}
Let $x$,$y$ $\in \mathbb{R}$ and $\sin$ the usual trigonometric sin function then:
\begin{equation*}
	\sin(x+y) = \sin(x)\cos(y)+\cos(x)\sin(y)
\end{equation*}
\end{Prop}
\begin{Proof}
	A simple geometric argument and periodicity of $\sin$ would give confirm the claim.
\end{Proof}


\begin{Prop}
	Let $a$,$b$,$\theta$ $\in \mathbb{R}$ and $\sin$,$\cos$ the usual trigonometric sin and cos functions then:
	\begin{equation*}
		a\sin \theta+b\cos \theta  = \sqrt{a^2+b^2}\sin(\theta + \varphi)
	\end{equation*}
	such that:
	\begin{equation*}
		\sin\varphi=b, \qquad \cos\varphi = a
	\end{equation*}
	\end{Prop}
	\begin{Proof}
		A simple geometric argument and periodicity of $\sin$ would confirm the claim.
	\end{Proof}

	\begin{Thm}\label{theorem:euler formula}
    Let $\theta \in \mathbb{R}$ and $\mathrm{i} \coloneqq (0,1) \in \mathbb{C}$ with the usual field operations associated with 
	complex field. Then:
	\begin{equation*}
		\mathrm{e}^{\mathrm{i}\theta} = \cos \theta +  \mathrm{i}\sin \theta
	\end{equation*}
	\end{Thm}
	\begin{Proof}
		Expanding the $\exp$ function and separating the so-called Real and Imaginary part and convergance arguments 
	on infinite series would confirm the claim\cite{Rudin1987}\cite{Stein2003}. 
	\end{Proof}


	\begin{Prop}\label{theorem:min distance}
		Let $\varphi \in \mathbb{R}$, $x,z \in \mathbb{C}^n$, $w \coloneqq (z,x)_X \coloneqq \operatorname{Re}(w)+\mathrm{i}\operatorname{Im}(w)$ where $(z,x)_X$ is 
		the usual scalar product associated with such vector spaces, and $\left|\cdot\right|_X$ the induced norm using the scalar product on the vector space $X$, then the expression
		\begin{equation*}
			f(\varphi) \coloneqq \left|x-\mathrm{e}^{-\mathrm{i}\varphi}z\right|^2_X
		\end{equation*}
		has a minimum and the minimum can be calculated in a closed form manner.
		\end{Prop}
		\begin{Proof}
			$f(\varphi)$ is continuous and periodic therefore it will attain its minimum and maximum for $\varphi^\ast \in [0,2\pi)$\cite{Rudin1976}\cite{Rudin1987}.
			\begin{equation*}
				\begin{split}
				f(\varphi) &\coloneqq \left|x-\mathrm{e}^{-\mathrm{i}\varphi}z\right|^2_X = 
				\left(x-\mathrm{e}^{-\mathrm{i}\varphi}z\right)_X\left(x-\mathrm{e}^{-\mathrm{i}\varphi}z\right)_X\\
						   &= \left(x,x\right)_X - \mathrm{e}^{\mathrm{i}\varphi}\left(x,z\right)_X-\mathrm{e}^{-\mathrm{i}\varphi}\left(z,x\right)_X+\left(z,z\right)_X \\
                		   &= \left(x,x\right)_X - (\cos(\varphi)+\mathrm{i}\sin(\varphi))\left(\operatorname{Re}(w) -\mathrm{i}\operatorname{Im}(w)\right)\\
						   &+ \left(z,z\right)_X - (\cos(\varphi)+\mathrm{i}\sin(\varphi))\left(\operatorname{Re}(w) +\mathrm{i}\operatorname{Im}(w)\right)\\
						   &= \left(x,x\right)_X - 2\left(\cos\varphi\operatorname{Re}(w)+\sin\varphi\operatorname{Im}(w)\right)+ \left(z,z\right)_X
				\end{split}
			  \end{equation*}
			  \begin{equation*}
				\begin{split}
				\frac{\mathrm{d}f(\varphi)}{\mathrm{d}\varphi} &\coloneqq - 2\left(-\sin\varphi\operatorname{Re}(w)+\cos\varphi\operatorname{Im}(w)\right) = 2\sqrt{\operatorname{Re}(w)^2+\operatorname{Im}(w)^2}\sin(\varphi-\theta)\\ 
				\end{split}
			  \end{equation*}
			  where $\cos\theta = \operatorname{Re}(w)$ and $\sin\theta = \operatorname{Im}(w)$
			  \begin{equation*}
				\begin{split}
				\frac{\mathrm{d}^2f(\varphi)}{\mathrm{d}\varphi^2} &\coloneqq - 2\left(-\cos\varphi\operatorname{Re}(w)-\sin\varphi\operatorname{Im}(w)\right) = -2\sqrt{\operatorname{Re}(w)^2+\operatorname{Im}(w)^2}\cos(\varphi-\theta)\\ 
				\end{split}
			  \end{equation*}
			  where $\cos\theta = \operatorname{Re}(w)$ and $\sin\theta = \operatorname{Im}(w)$.
			  For $\varphi^\ast-\varphi = (2k+1)\pi, k \in \mathbb{Z}$ we would arrive at the minimum.

		\end{Proof}

