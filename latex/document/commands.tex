\newcommand{\srp}{\emph{sparse recovery problem}\xspace}
\newcommand{\SRP}{\emph{Sparse Recovery Problem}\xspace}
\newcommand{\pr}{\emph{phase retrieval}\xspace}
\newcommand{\PR}{\emph{Phase Retrieval}\xspace}
\newcommand{\ai}{artificial intelligence\xspace}
\newcommand{\AI}{Artificial intelligence\xspace}
\newcommand{\AIabbr}{AI\xspace}
\newcommand{\ml}{machine learning\xspace}
\newcommand{\ML}{Machine learning\xspace}
\newcommand{\MLabbr}{ML\xspace}
\newcommand{\dl}{deep learning\xspace}
\newcommand{\DL}{Deep learning\xspace}
\newcommand{\du}{\emph{deep unfolding}\xspace}
\newcommand{\DU}{\emph{Deep Unfolding}\xspace}
\newcommand{\au}{\emph{algorithm unrolling}\xspace}
\newcommand{\AU}{\emph{Algorithm Unrolling}\xspace}
\newcommand{\DLabbr}{DL\xspace}
\newcommand{\nn}{neural network\xspace}
\newcommand{\nns}{neural networks\xspace}
\newcommand{\Nn}{Neural network\xspace}
\newcommand{\Nns}{Neural networks\xspace}
\newcommand{\dataset}{dataset\xspace}
\newcommand{\datasets}{datasets\xspace}
\newcommand{\runtime}{runtime\xspace}
\newcommand{\runtimes}{runtimes\xspace}
\newcommand{\Runtime}{Runtime\xspace}
\newcommand{\heldout}{held-out\xspace}
\newcommand{\Heldout}{Held-out\xspace}
\newcommand{\ta}{training algorithm\xspace}
\newcommand{\tas}{training algorithms\xspace}
\newcommand{\Ta}{Training algorithm\xspace}
\newcommand{\Tas}{Training algorithms\xspace}
\newcommand{\wl}{workload\xspace}
\newcommand{\wls}{workloads\xspace}
\newcommand{\Wl}{Workload\xspace}
\newcommand{\Wls}{Workloads\xspace}
\newcommand{\ho}{\emph{hyperparameter optimization}\xspace}
\newcommand{\HO}{\emph{Hyperparameter Optimization}\xspace}
\newcommand{\hp}{\emph{hyperparameter}\xspace}
\newcommand{\HP}{\emph{Hyperparameter}\xspace}
\newcommand{\hps}{\emph{hyperparameters}\xspace}
\newcommand{\HPs}{\emph{Hyperparameters}\xspace}
\newcommand{\ruleset}{ruleset\xspace}
\newcommand{\rulesets}{rulesets\xspace}
\newcommand{\quasirandom}{quasirandom\xspace}

\newcommand{\adam}{\textsc{\mbox{Adam}}\xspace}
\newcommand{\adamw}{\textsc{\mbox{AdamW}}\xspace}
\newcommand{\sgd}{\textsc{\mbox{SGD}}\xspace}
\newcommand{\heavyball}{\textsc{\mbox{Heavy Ball}}\xspace}
\newcommand{\nesterov}{\textsc{\mbox{Nesterov}}\xspace}
\newcommand{\momentum}{\textsc{\mbox{Momentum}}\xspace}
\newcommand{\nadam}{\textsc{\mbox{Nadam}}\xspace}
\newcommand{\nadamw}{\textsc{\mbox{NadamW}}\xspace}
\newcommand{\shampoo}{\textsc{\mbox{Shampoo}}\xspace}
\newcommand{\distshampoo}{\textsc{Distributed \mbox{Shampoo}}\xspace}
\newcommand{\kfac}{\textsc{\mbox{K-FAC}}\xspace}
\newcommand{\adagrad}{\textsc{\mbox{AdaGrad}}\xspace}
\newcommand{\radam}{\textsc{\mbox{RAdam}}\xspace}
\newcommand{\lars}{\textsc{\mbox{LARS}}\xspace}
\newcommand{\lamb}{\textsc{\mbox{LAMB}}\xspace}
\newcommand{\rmsprop}{\textsc{\mbox{RMSProp}}\xspace}
\newcommand{\adafactor}{\textsc{\mbox{Adafactor}}\xspace}
\newcommand{\sam}{\textsc{\mbox{SAM}}\xspace}
\newcommand{\samadam}{\textsc{\mbox{SAM}(w.~\adam)}\xspace}
\newcommand{\betaone}{$\beta_1$}
\newcommand{\betatwo}{$\beta_2$}
\newcommand{\optlisttext}{\textsc{\mbox{OptList}}\xspace}
\newcommand{\optlist}{\textsc{\mbox{OptList}}}

\newcommand{\cosinedecay}{cosine decay\xspace}
\newcommand{\cosinelrdecay}{cosine learning rate decay\xspace}
\newcommand{\warmup}{warmup\xspace}
\newcommand{\Warmup}{Warmup\xspace}
\newcommand{\lineardecay}{linear decay\xspace}
\newcommand{\linearlrdecay}{linear learning rate decay\xspace}
\newcommand{\constantschedule}{constant\xspace}
\newcommand{\constantlr}{constant learning rate\xspace}

\newcommand{\wcd}{\warmup$\!+\!$ \cosinedecay}
\newcommand{\wldc}{\warmup$\!+\!$ \lineardecay$\!+\!$ \constantschedule}

\newcommand{\imagenetresnet}{\textsc{ImageNet ResNet-50}\xspace}
\newcommand{\imagenetvit}{\textsc{ImageNet ViT}\xspace}
\newcommand{\wmttransformer}{\textsc{WMT Transformer}\xspace}
\newcommand{\librideepspeech}{\textsc{LibriSpeech DeepSpeech}\xspace}
\newcommand{\libriconformer}{\textsc{LibriSpeech Conformer}\xspace}
\newcommand{\criteodlrm}{\textsc{Criteo 1TB DLRM small}\xspace}
\newcommand{\ogbggnn}{\textsc{OGBG GNN}\xspace}
\newcommand{\fastmriunet}{\textsc{fastMRI U-Net}\xspace}

\newcommand{\imagenet}{\textsc{ImageNet}\xspace}
\newcommand{\wmt}{\textsc{WMT}\xspace}
\newcommand{\librispeech}{\textsc{LibriSpeech}\xspace}
\newcommand{\criteo}{\textsc{Criteo 1TB}\xspace}
\newcommand{\ogbg}{\textsc{OGBG}\xspace}
\newcommand{\fastmri}{\textsc{fastMRI}\xspace}

\newcommand{\cifar}{\textsc{CIFAR}\xspace}
\newcommand{\cifarten}{\textsc{CIFAR-10}\xspace}
\newcommand{\cifarhun}{\textsc{CIFAR-100}\xspace}
\newcommand{\svhn}{\textsc{SVHN}\xspace}
\newcommand{\mnist}{\textsc{MNIST}\xspace}

\newcommand{\resnetfifty}{\textsc{ResNet-50}\xspace}
\newcommand{\resnet}{\textsc{ResNet}\xspace}
\newcommand{\resnets}{\textsc{ResNet}s\xspace}
\newcommand{\wideresnet}{\textsc{Wide ResNet}\xspace}
\newcommand{\vit}{\textsc{ViT}\xspace}
\newcommand{\vitfull}{\textsc{Vision Transformer}\xspace}
\newcommand{\transformer}{\textsc{Transformer}\xspace}
\newcommand{\deepspeech}{\textsc{DeepSpeech}\xspace}
\newcommand{\conformer}{\textsc{Conformer}\xspace}
\newcommand{\dlrmsmall}{\textsc{DLRMsmall}\xspace}
\newcommand{\gnn}{\textsc{GNN}\xspace}
\newcommand{\unet}{\textsc{U-Net}\xspace}

\newcommand{\resnetvtwo}{\textsc{ResNetV2}\xspace}
\newcommand{\resnettwohun}{\textsc{ResNet-200}\xspace}
\newcommand{\dlrm}{\textsc{DLRM}\xspace}

\newcommand{\preln}{\textsc{Pre-LN}\xspace}
\newcommand{\prelnfull}{\textsc{Pre-Layer Norm}\xspace}
\newcommand{\postln}{\textsc{Post-LN}\xspace}
\newcommand{\postlnfull}{\textsc{Post-Layer Norm}\xspace}


\newcommand{\batchnorm}{batch normalization\xspace}
\newcommand{\layernorm}{layer normalization\xspace}
\newcommand{\Layernorm}{Layer normalization\xspace}
\newcommand{\instancenorm}{instance normalization\xspace}
\newcommand{\relu}{ReLU\xspace}
\newcommand{\silu}{SiLU\xspace}
\newcommand{\gelu}{GELU\xspace}
\newcommand{\Tanh}{TanH\xspace}
\newcommand{\leakyrelu}{Leaky ReLU\xspace}
\newcommand{\dropout}{dropout\xspace}

\newcommand{\bleu}{BLEU\xspace}
\newcommand{\sacrebleu}{sacreBLEU\xspace}
\newcommand{\ssim}{SSIM\xspace}

\newcommand{\rulesurl}{\href{https://github.com/mlcommons/algorithmic-efficiency/blob/main/RULES.md}{github.com/mlcommons/algorithmic-efficiency/blob/main/RULES.md}\xspace}
\newcommand{\mlccodebase}{https://github.com/mlcommons/algorithmic-efficiency}
\newcommand{\initcodebase}{https://github.com/google/init2winit}

\newcommand{\deepobs}{\textsc{DeepOBS}\xspace}
\newcommand{\backpack}{\textsc{BackPACK}\xspace}
\newcommand{\jraph}{\textsc{Jraph}\xspace}
\newcommand{\unix}{\textsc{UNIX}\xspace}
% \newcommand{\gnu}{\textsc{GNU}\xspace}
% \newcommand{\cuda}{\textsc{CUDA}\xspace}
\newcommand{\python}{\textsc{Python}\xspace}
% \newcommand{\adam}{\textsc{Adam}\xspace}
\newcommand{\pytorch}{\textsc{PyTorch}\xspace}
\newcommand{\awk}{\textsc{Awk}\xspace}
\newcommand{\bash}{\textsc{Bash}\xspace}

\newcommand{\tensorflow}{\textsc{TensorFlow}\xspace}
\newcommand{\keras}{\textsc{Keras}\xspace}
\newcommand{\optuna}{\textsc{Optuna}\xspace}
\newcommand{\jax}{\textsc{JAX}\xspace}
\newcommand{\flax}{\textsc{Flax}\xspace}
\newcommand{\mlperf}{\textsc{MLPerf}\texttrademark\xspace}
\newcommand{\mlperftraining}{\textsc{MLPerf\texttrademark\xspace Training}\xspace}
\newcommand{\dawnbench}{\textsc{DAWNBench}\xspace}
\newcommand{\dlbs}{\textsc{Deep Learning Benchmark Suite}\xspace}
\newcommand{\deepbench}{\textsc{DeepBench}\xspace}
\newcommand{\tbdnn}{\textsc{Training Benchmark for DNNs}\xspace}
\newcommand{\benchopt}{\textsc{Benchopt}\xspace}