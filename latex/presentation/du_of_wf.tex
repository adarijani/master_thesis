%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% DU of WF*%% %%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section[DU/AU of WF*]{Deep Unfolding of Wirtinger Flow Variants}
\begin{frame}
  \frametitle{The Gist of Most WF Algorithms Algorithmically}
  Let the update rule be of the form:
  \begin{equation}
    \boldsymbol{z}_{k+1} = \boldsymbol{z}_k - \tau\boldsymbol{\theta}[\boldsymbol{z}_k,\boldsymbol{A},\boldsymbol{A^*},\varphi]
  \end{equation}
  where $\boldsymbol{\theta}[\boldsymbol{z}_k,\boldsymbol{A},\boldsymbol{A^*},\varphi]$ is a mapping that gives a vector as an output 
  $\in\mathbb{C}^N$ and $\tau$ is the step size that was proposed by the respective algorithm.

  % and Unrolled/Unfolded $L$ times
  
  % where $\boldsymbol{\theta}$ is of the same size and structure as $\boldsymbol{z}$ and $\tau$ is the step size that was proposed by the respective algorithm. Assume that the algorithms are unfolded/unrolled $L$ times, then we considered the following 
  % scenarios by substituting $\tau$ with:
  
\end{frame}



% \begin{frame}
%   \frametitle{Application of RWF in Diffracted Imaging}
%     \begin{figure}[!htbp]
%       \centering
%       % \captionsetup{justification=centering}
%       \includegraphics[width=0.30\textwidth]{../document/images/rwf_sat_phone/000_025_32_original.png}
%   %   \caption{{WF}(left) vs {RWF}(right)}
%     \label{image:rwf}
%     \end{figure}
%   \end{frame}

% \begin{frame}
%   \frametitle{WF(Left) vs TWF(Right)}
%     \begin{figure}[!htbp]
%       \centering
%       % \captionsetup{justification=centering}
%       \includegraphics[width=0.5\textwidth]{../document/images/cdp/out_wf_twf.png}
%   %   \caption{{WF}(left) vs {RWF}(right)}
%     \label{images:wf_vs_twf_cdp}
%     \end{figure}
%   \end{frame}
% \begin{frame}
% \frametitle{RWF(Left) vs TWF(Right)}
%  \begin{figure}[!htbp]
%    \centering
%    % \captionsetup{justification=centering}
%    \includegraphics[width=0.5\textwidth]{../document/images/cdp/out_twf_rwf.png}
% %   \caption{{WF}(left) vs {RWF}(right)}
%  \label{image:twf_vs_rwf_cdp}
%  \end{figure}
% \end{frame}

\begin{frame}
    \frametitle{What Are We Trying to Do?}
    \begin{center}
      \Large{We try to gain some kind of improvements in the original algorithms by either optimizing Some parameters
      or by changing the Iteration a bit while not destroying the innate nonlinearities.}  
    \end{center}
\end{frame}

\begin{frame}
  \frametitle{Machine Learning Setup}
  \begin{itemize}
    \pause
    \item RWF as the algorithm to unfold.
    \pause
    \item Unfold the RWF 30 times and name it URWF.
    \pause
    \item 100 input-output as a synthetic dataset.
    \pause 
    \item Usual tricks not to end up with a dictionary
    \pause 
    \item Using $10^{-3}$ as the pseudo learning rate
    \pause 
    \item Using 2 as the mini-batch SGD size
    \pause 
    \item Passing the whole dataset 50 times through your model.
    \pause 
    \item Track the RWF/URWF error on train and test data. 
    \pause 
    \item Eyeball the finished plots.
  \end{itemize}
\end{frame}

\begin{frame}
    \frametitle{First Scenario}
    \begin{center}
      $\boldsymbol{z}_{k+1} = \boldsymbol{z}_k - \tau\boldsymbol{\theta}[\boldsymbol{z}_k,\boldsymbol{A},\boldsymbol{A^*},\varphi]$ 
      and learning the single scalar $\tau \in \mathbb{R}$ as to try and find a better gradient descent with constant step size,  
    \end{center}    
\end{frame}

\begin{frame}
  \begin{figure}
    \frametitle{URWF, $\tau,L=30,lr=0.001$}
    \centering
    % \captionsetup{justification=centering}
    \resizebox{0.9\textwidth}{!}{\input{../document/tikz/rwf/rwf_s_00_l_30_e_50_lr_0.001.tex}}
    % \caption{The Schematic Unfolding of an Iterative Algorithm}
    \label{fig:rwf_s_00_l_30_lr_0.001}
  \end{figure}
\end{frame}

\begin{frame}
  \frametitle{Second Scenario}
  \begin{center}
    $\boldsymbol{z}_{k+1} = \boldsymbol{z}_k - \tau_k\boldsymbol{\theta}[\boldsymbol{z}_k,\boldsymbol{A},\boldsymbol{A^*},\varphi]$
    and learning $L$ scalars $\tau_k\in\mathbb{R}$ as to try and find a better adaptive gradient descent with large step sizes when possible 
    and small step sizes while being in \emph{stiff} regions, 
  \end{center}
  
\end{frame}

\begin{frame}
  \begin{figure}
    \frametitle{URWF, $\tau_k,L=30,lr=0.001$}
    \centering
    % \captionsetup{justification=centering}
    \resizebox{0.9\textwidth}{!}{\input{../document/tikz/rwf/rwf_s_01_l_30_e_50_lr_0.001.tex}}
    % \caption{The Schematic Unfolding of an Iterative Algorithm}
    \label{fig:rwf_s_01_l_30_lr_0.001}
  \end{figure}
\end{frame}

\begin{frame}
  \frametitle{Third Scenario}
  \begin{center}
    $\boldsymbol{z}_{k+1} = \boldsymbol{z}_k - \boldsymbol{S}\boldsymbol{\theta}[\boldsymbol{z}_k,\boldsymbol{A},\boldsymbol{A^*},\varphi]$
    and learning a single semi-positive definite matrix $\boldsymbol{S}\in \mathbb{R}^{N \times N}$ as to try and find a better descent direction while 
    ensuring being always on the descent direction by the semi-positive definite constraint,
  \end{center}
\end{frame}

\begin{frame}
  \begin{figure}
    \frametitle{URWF, $\boldsymbol{S},L=30,lr=0.001$}
    \centering
    % \captionsetup{justification=centering}
    \resizebox{0.9\textwidth}{!}{\input{../document/tikz/rwf/rwf_s_03_l_30_e_50_lr_0.001.tex}}
    % \caption{The Schematic Unfolding of an Iterative Algorithm}
    \label{fig:rwf_s_03_l_30_lr_0.001}
  \end{figure}
\end{frame}



\begin{frame}
  \frametitle{Fourth Scenario}
  \begin{center}
    $\boldsymbol{z}_{k+1} = \boldsymbol{z}_k - \boldsymbol{M}\boldsymbol{\theta}[\boldsymbol{z}_k,\boldsymbol{A},\boldsymbol{A^*},\varphi]$
    and learning a single general matrix $\boldsymbol{M}\in \mathbb{R}^{N \times N}$ as to try and find a better descent direction while 
    while not forcing the semi-positive definite constraint and hoping for the best,
  \end{center}
\end{frame}

\begin{frame}
  \begin{figure}
    \frametitle{URWF, $\boldsymbol{M},L=30,lr=0.001$}
    \centering
    % \captionsetup{justification=centering}
    \resizebox{0.9\textwidth}{!}{\input{../document/tikz/rwf/rwf_s_02_l_30_e_50_lr_0.001.tex}}
    % \caption{The Schematic Unfolding of an Iterative Algorithm}
    \label{fig:rwf_s_02_l_30_lr_0.001}
  \end{figure}
\end{frame}




\begin{frame}
  \frametitle{Fifth Scenario}
  \begin{center}
    $\boldsymbol{z}_{k+1} = \boldsymbol{z}_k - \tau_k\boldsymbol{S}\boldsymbol{\theta}[\boldsymbol{z}_k,\boldsymbol{A},\boldsymbol{A^*},\varphi]$
    and learning a single semi-positive definite matrix $\boldsymbol{S}\in \mathbb{R}^{N \times N}$ and $L$ scalars $\tau_k \in \mathbb{R}$ as to try and find a 
    better descent direction with variable step sizes while \emph{trying} to ensure to be always on the descent direction by the 
    semi-positive definite constraint (there is the possibility that the optimizer goes for a negative step sizes $\tau_k \in \mathbb{R}$), 
  \end{center}  
\end{frame}

\begin{frame}
  \begin{figure}
    \frametitle{URWF, $\tau_k\boldsymbol{S},L=30,lr=0.001$}
    \centering
    % \captionsetup{justification=centering}
    \resizebox{0.9\textwidth}{!}{\input{../document/tikz/rwf/rwf_s_05_l_30_e_50_lr_0.001.tex}}
    % \caption{The Schematic Unfolding of an Iterative Algorithm}
    \label{fig:rwf_s_05_l_30_lr_0.001}
  \end{figure}
\end{frame}




\begin{frame}
  \frametitle{Sixth Scenario}
  \begin{center}
    $\boldsymbol{z}_{k+1} = \boldsymbol{z}_k - \tau_k\boldsymbol{M}\boldsymbol{\theta}[\boldsymbol{z}_k,\boldsymbol{A},\boldsymbol{A^*},\varphi]$
    and learning a single general matrix $\boldsymbol{M}\in \mathbb{R}^{N \times N}$ and $L$ scalars $\tau_k \in \mathbb{R}$ as to try and find a 
    better descent direction with variable step sizes while not forcing the semi-positive definite constraint and hoping for the best, 
  \end{center}
  
\end{frame}

\begin{frame}
  \begin{figure}
    \frametitle{URWF, $\tau_{k}\boldsymbol{M},L=30,lr=0.001$}
    \centering
    % \captionsetup{justification=centering}
    \resizebox{0.9\textwidth}{!}{\input{../document/tikz/rwf/rwf_s_04_l_30_e_50_lr_0.001.tex}}
    % \caption{The Schematic Unfolding of an Iterative Algorithm}
    \label{fig:rwf_s_04_l_30_lr_0.001}
  \end{figure}
\end{frame}




\begin{frame}
  \frametitle{Seventh Scenario}
  \begin{center}
    $\boldsymbol{z}_{k+1} = \boldsymbol{z}_k - \boldsymbol{S}_k\boldsymbol{\theta}[\boldsymbol{z}_k,\boldsymbol{A},\boldsymbol{A^*},\varphi]$ 
    and learning $L$ semi-positive definite matrices $\boldsymbol{S}\in \mathbb{R}^{N \times N}$ as to try and find a better descent direction while 
    ensuring being always on the descent direction by the semi-positive definite constraint,
  \end{center}
  
\end{frame}

\begin{frame}
  \begin{figure}
    \frametitle{URWF, $\boldsymbol{S}_k,L=30,lr=0.001$}
    \centering
    % \captionsetup{justification=centering}
    \resizebox{0.9\textwidth}{!}{\input{../document/tikz/rwf/rwf_s_07_l_30_e_50_lr_0.001.tex}}
    % \caption{The Schematic Unfolding of an Iterative Algorithm}
    \label{fig:rwf_s_07_l_30_lr_0.001}
  \end{figure}
\end{frame}


\begin{frame}
  \frametitle{Eighth Scenario}
  \begin{center}
    $\boldsymbol{z}_{k+1} = \boldsymbol{z}_k - \boldsymbol{M}_k\boldsymbol{\theta}[\boldsymbol{z}_k,\boldsymbol{A},\boldsymbol{A^*},\varphi]$ 
    and learning $L$ general matrices $\boldsymbol{M}\in \mathbb{R}^{N \times N}$ as to try and find a better descent direction while 
    while not forcing the semi-positive definite constraint and hoping for the best,
  \end{center}
\end{frame}

\begin{frame}
  \begin{figure}
    \frametitle{URWF, $\boldsymbol{M}_k,L=30,lr=0.001$}
    \centering
    % \captionsetup{justification=centering}
    \resizebox{0.9\textwidth}{!}{\input{../document/tikz/rwf/rwf_s_06_l_30_e_50_lr_0.001.tex}}
    % \caption{The Schematic Unfolding of an Iterative Algorithm}
    \label{fig:rwf_s_06_l_30_lr_0.001}
  \end{figure}
\end{frame}